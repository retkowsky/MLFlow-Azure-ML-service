{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model as Azure Machine Learning Web Service using MLflow\n",
    "\n",
    "This example shows you how to use mlflow together with Azure Machine Learning services for deploying a model as a web service. You'll learn how to:\n",
    "\n",
    " 1. Retrieve a previously trained scikit-learn model\n",
    " 2. Create a Docker image from the model\n",
    " 3. Deploy the model as a web service on Azure Container Instance\n",
    " 4. Make a scoring request against the web service.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites and Set-up\n",
    "\n",
    "This notebook requires you to first complete the [Use MLflow with Azure Machine Learning for Local Training Run](../train-local/train-local.ipnyb) or [Use MLflow with Azure Machine Learning for Remote Training Run](../train-remote/train-remote.ipnyb) notebook, so as to have an experiment run with uploaded model in your Azure Machine Learning Workspace.\n",
    "\n",
    "Also install following packages if you haven't already\n",
    "\n",
    "```\n",
    "pip install azureml-mlflow pandas\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-09\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "datedujour = time.strftime(\"%Y-%m-%d\")\n",
    "print(datedujour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.76\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import azureml.mlflow\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to workspace and set MLflow tracking URI\n",
    "\n",
    "Setting the tracking URI is required for retrieving the model and creating an image using the MLflow APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve model from previous run\n",
    "\n",
    "Let's retrieve the experiment from training notebook, and list the runs within that experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(Experiment: MLFlow,\n",
       " Id: MLFlow_1575898279_b8568104,\n",
       " Type: azureml.scriptrun,\n",
       " Status: Completed), Run(Experiment: MLFlow,\n",
       " Id: 8f636596-574c-4ace-93e2-ae12a6ec4700,\n",
       " Type: None,\n",
       " Status: Completed), Run(Experiment: MLFlow,\n",
       " Id: c7295939-551a-4756-8acc-9dbf650474d9,\n",
       " Type: None,\n",
       " Status: Completed)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"MLFlow\"\n",
    "exp = ws.experiments[experiment_name]\n",
    "\n",
    "runs = list(exp.get_runs())\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's select the most recent training run and find its ID. You also need to specify the path in run history where the model was saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = runs[0].id\n",
    "model_save_path = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Docker image\n",
    "\n",
    "To create a Docker image with Azure Machine Learning for Model Management, use ```mlflow.azureml.build_image``` method. Specify the model path, your workspace, run ID and other parameters.\n",
    "\n",
    "**MLflow automatically recognizes the model framework as scikit-learn**, and creates the scoring logic and includes library dependencies for you.\n",
    "\n",
    "Note that the image creation can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model diabetes-sklearn-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/12/09 14:40:29 INFO mlflow.azureml: Registered an Azure Model with name: `diabetes-sklearn-model` and version: `5`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/12/09 14:40:31 INFO mlflow.azureml: Building an Azure Container Image with name: `diabetes-sklearn-image` and version: `5`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running................................................................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image diabetes-sklearn-image:5, operation \"Succeeded\"\n",
      "CPU times: user 842 ms, sys: 63 ms, total: 905 ms\n",
      "Wall time: 8min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import mlflow.azureml\n",
    "\n",
    "azure_image, azure_model = mlflow.azureml.build_image(model_uri=\"runs:/{}/{}\".format(runid, model_save_path),\n",
    "                                                      workspace=ws,\n",
    "                                                      model_name='diabetes-sklearn-model',\n",
    "                                                      image_name='diabetes-sklearn-image',\n",
    "                                                      synchronous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy web service\n",
    "\n",
    "Let's use Azure Machine Learning SDK to deploy the image as a web service. \n",
    "\n",
    "First, specify the deployment configuration. Azure Container Instance is a suitable choice for a quick dev-test deployment, while Azure Kubernetes Service is suitable for scalable production deployments.\n",
    "\n",
    "Then, deploy the image using Azure Machine Learning SDK's ```deploy_from_image``` method.\n",
    "\n",
    "Note that the deployment can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 62 µs, total: 62 µs\n",
      "Wall time: 66.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                                memory_gb=1, \n",
    "                                                tags={\"method\" : \"sklearn\"}, \n",
    "                                                description='Diabetes model',\n",
    "                                                location='eastus2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 235 ms, sys: 47.1 ms, total: 282 ms\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Deploy the image to Azure Container Instances (ACI) for real-time serving\n",
    "webservice = Webservice.deploy_from_image(\n",
    "    image=azure_image, workspace=ws, name=\"diabetes-aci-model\", deployment_config=aci_config)\n",
    "\n",
    "\n",
    "webservice.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://ml.azure.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make a scoring request\n",
    "\n",
    "Let's take the first few rows of test data and score them using the web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Scoring Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://94d70d34-9e0c-4aeb-bf20-53e8fb5d54df.eastus2.azurecontainer.io/score'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webservice.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow-based web service for scikit-learn model requires the data to be converted to Pandas DataFrame, and then serialized as JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    [0.01991321,  0.05068012,  0.10480869,  0.07007254, -0.03596778,\n",
    "     -0.0266789 , -0.02499266, -0.00259226,  0.00371174,  0.04034337],\n",
    "    [-0.01277963, -0.04464164,  0.06061839,  0.05285819,  0.04796534,\n",
    "     0.02937467, -0.01762938,  0.03430886,  0.0702113 ,  0.00720652],\n",
    "    [ 0.03807591,  0.05068012,  0.00888341,  0.04252958, -0.04284755,\n",
    "     -0.02104223, -0.03971921, -0.00259226, -0.01811827,  0.00720652]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "test_rows_as_json = pd.DataFrame(tests).to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[0,1,2,3,4,5,6,7,8,9],\"index\":[0,1,2],\"data\":[[0.01991321,0.05068012,0.10480869,0.07007254,-0.03596778,-0.0266789,-0.02499266,-0.00259226,0.00371174,0.04034337],[-0.01277963,-0.04464164,0.06061839,0.05285819,0.04796534,0.02937467,-0.01762938,0.03430886,0.0702113,0.00720652],[0.03807591,0.05068012,0.00888341,0.04252958,-0.04284755,-0.02104223,-0.03971921,-0.00259226,-0.01811827,0.00720652]]}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rows_as_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction =  [235.11371087161342, 246.8015254559213, 163.6854179229191]\n",
      "CPU times: user 792 µs, sys: 3.43 ms, total: 4.22 ms\n",
      "Wall time: 288 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = webservice.run(test_rows_as_json)\n",
    "print(\"Model Prediction = \", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can diagnose the web service using ```get_logs``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-09T14:54:00,370466272+00:00 - rsyslog/run \\n2019-12-09T14:54:00,373824678+00:00 - gunicorn/run \\n2019-12-09T14:54:00,375149781+00:00 - iot-server/run \\n2019-12-09T14:54:00,375948882+00:00 - nginx/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2019-12-09T14:54:00,630162229+00:00 - iot-server/finish 1 0\\n2019-12-09T14:54:00,635952739+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.6.0\\nListening at: http://127.0.0.1:31311 (10)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 45\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2019-12-09 14:54:06,912 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2019-12-09 14:54:06,912 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2019-12-09 14:54:06,912 | azureml.core.model | DEBUG | Using passed in version 5\\n2019-12-09 14:54:06,912 | azureml.core.model | DEBUG | Found model path at azureml-models/diabetes-sklearn-model/5/model\\nUsers\\'s init has completed successfully\\n/var/azureml-app/execution_script.py:12: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\\n  model = load_pyfunc(model_path)\\nScoring timeout is found from os.environ: 60000 ms\\nValidation Request Content-Type\\nReceived input: \\nHeaders passed in (total 11):\\n\\tHost: localhost:5001\\n\\tX-Real-Ip: 127.0.0.1\\n\\tX-Forwarded-For: 127.0.0.1\\n\\tX-Forwarded-Proto: http\\n\\tConnection: close\\n\\tContent-Length: 0\\n\\tUser-Agent: python-requests/2.22.0\\n\\tAccept: */*\\n\\tAccept-Encoding: gzip, deflate\\n\\tContent-Type: application/json\\n\\tX-Ms-Request-Id: 9f165160-9bbb-4cd0-914e-c4991065d1cc\\nScoring Timer is set to 60.0 seconds\\nEncountered Exception: Traceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 73, in parse_json_input\\n    return pd.read_json(json_input, orient=orient, dtype=False)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 592, in read_json\\n    result = json_reader.read()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 717, in read\\n    obj = self._get_object_parser(self.data)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 739, in _get_object_parser\\n    obj = FrameParser(json, **kwargs).parse()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 849, in parse\\n    self._parse_no_numpy()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 1098, in _parse_no_numpy\\n    for k, v in loads(json, precise_float=self.precise_float).items()\\nValueError: Expected object or value\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/var/azureml-server/app.py\", line 226, in run_scoring\\n    response = invoke_user_with_timer(service_input, request_headers)\\n  File \"/var/azureml-server/app.py\", line 296, in invoke_user_with_timer\\n    result = user_main.run(**params)\\n  File \"/var/azureml-app/main.py\", line 30, in run\\n    return_obj = driver_module.run(**arguments)\\n  File \"/var/azureml-app/execution_script.py\", line 16, in run\\n    input_df = parse_json_input(json_input=json_input, orient=\"split\")\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 81, in parse_json_input\\n    error_code=MALFORMED_REQUEST)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 144, in _handle_serving_error\\n    stack_trace=traceback_buf.getvalue()))\\n  File \"/opt/miniconda/lib/python3.6/site-packages/six.py\", line 696, in reraise\\n    raise value\\nmlflow.exceptions.MlflowException: Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient=\\'split\\')` method.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File \"/var/azureml-server/app.py\", line 143, in score_realtime\\n    return run_scoring(service_input, request.headers, request.environ.get(\\'REQUEST_ID\\', \\'00000000-0000-0000-0000-000000000000\\'))\\n  File \"/var/azureml-server/app.py\", line 239, in run_scoring\\n    raise RunFunctionException(str(exc))\\nrun_function_exception.RunFunctionException\\n\\n500\\n127.0.0.1 - - [09/Dec/2019:14:55:50 +0000] \"POST /score HTTP/1.0\" 500 208 \"-\" \"python-requests/2.22.0\"\\nException in worker process\\nTraceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 557, in spawn_worker\\n    worker.init_process()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 132, in init_process\\n    self.run()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 124, in run\\n    self.run_for_one(timeout)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 83, in run_for_one\\n    self.wait(timeout)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 35, in wait\\n    ret = select.select(self.wait_fds, [], [], timeout)\\n  File \"/var/azureml-server/app.py\", line 266, in alarm_handler\\n    raise TimeoutException(error_message)\\ntimeout_exception.TimeoutException\\nWorker exiting (pid: 45)\\nworker timeout is set to 300\\nBooting worker with pid: 50\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2019-12-09 14:56:52,806 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2019-12-09 14:56:52,806 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2019-12-09 14:56:52,806 | azureml.core.model | DEBUG | Using passed in version 5\\n2019-12-09 14:56:52,806 | azureml.core.model | DEBUG | Found model path at azureml-models/diabetes-sklearn-model/5/model\\nUsers\\'s init has completed successfully\\n/var/azureml-app/execution_script.py:12: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\\n  model = load_pyfunc(model_path)\\nScoring timeout is found from os.environ: 60000 ms\\nValidation Request Content-Type\\nReceived input: \\nHeaders passed in (total 11):\\n\\tHost: localhost:5001\\n\\tX-Real-Ip: 127.0.0.1\\n\\tX-Forwarded-For: 127.0.0.1\\n\\tX-Forwarded-Proto: http\\n\\tConnection: close\\n\\tContent-Length: 0\\n\\tUser-Agent: python-requests/2.22.0\\n\\tAccept: */*\\n\\tAccept-Encoding: gzip, deflate\\n\\tContent-Type: application/json\\n\\tX-Ms-Request-Id: a161e6ff-3d94-4eb8-9593-c6cc1fadc182\\nScoring Timer is set to 60.0 seconds\\nEncountered Exception: Traceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 73, in parse_json_input\\n    return pd.read_json(json_input, orient=orient, dtype=False)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 592, in read_json\\n    result = json_reader.read()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 717, in read\\n    obj = self._get_object_parser(self.data)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 739, in _get_object_parser\\n    obj = FrameParser(json, **kwargs).parse()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 849, in parse\\n    self._parse_no_numpy()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 1098, in _parse_no_numpy\\n    for k, v in loads(json, precise_float=self.precise_float).items()\\nValueError: Expected object or value\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/var/azureml-server/app.py\", line 226, in run_scoring\\n    response = invoke_user_with_timer(service_input, request_headers)\\n  File \"/var/azureml-server/app.py\", line 296, in invoke_user_with_timer\\n    result = user_main.run(**params)\\n  File \"/var/azureml-app/main.py\", line 30, in run\\n    return_obj = driver_module.run(**arguments)\\n  File \"/var/azureml-app/execution_script.py\", line 16, in run\\n    input_df = parse_json_input(json_input=json_input, orient=\"split\")\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 81, in parse_json_input\\n    error_code=MALFORMED_REQUEST)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 144, in _handle_serving_error\\n    stack_trace=traceback_buf.getvalue()))\\n  File \"/opt/miniconda/lib/python3.6/site-packages/six.py\", line 696, in reraise\\n    raise value\\nmlflow.exceptions.MlflowException: Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient=\\'split\\')` method.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File \"/var/azureml-server/app.py\", line 143, in score_realtime\\n    return run_scoring(service_input, request.headers, request.environ.get(\\'REQUEST_ID\\', \\'00000000-0000-0000-0000-000000000000\\'))\\n  File \"/var/azureml-server/app.py\", line 239, in run_scoring\\n    raise RunFunctionException(str(exc))\\nrun_function_exception.RunFunctionException\\n\\n500\\n127.0.0.1 - - [09/Dec/2019:14:56:55 +0000] \"POST /score HTTP/1.0\" 500 208 \"-\" \"python-requests/2.22.0\"\\nException in worker process\\nTraceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 557, in spawn_worker\\n    worker.init_process()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 132, in init_process\\n    self.run()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 124, in run\\n    self.run_for_one(timeout)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 83, in run_for_one\\n    self.wait(timeout)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 35, in wait\\n    ret = select.select(self.wait_fds, [], [], timeout)\\n  File \"/var/azureml-server/app.py\", line 266, in alarm_handler\\n    raise TimeoutException(error_message)\\ntimeout_exception.TimeoutException\\nWorker exiting (pid: 50)\\nworker timeout is set to 300\\nBooting worker with pid: 55\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2019-12-09 14:57:57,661 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2019-12-09 14:57:57,661 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2019-12-09 14:57:57,661 | azureml.core.model | DEBUG | Using passed in version 5\\n2019-12-09 14:57:57,662 | azureml.core.model | DEBUG | Found model path at azureml-models/diabetes-sklearn-model/5/model\\nUsers\\'s init has completed successfully\\n/var/azureml-app/execution_script.py:12: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\\n  model = load_pyfunc(model_path)\\nScoring timeout is found from os.environ: 60000 ms\\nValidation Request Content-Type\\nReceived input: \\nHeaders passed in (total 11):\\n\\tHost: localhost:5001\\n\\tX-Real-Ip: 127.0.0.1\\n\\tX-Forwarded-For: 127.0.0.1\\n\\tX-Forwarded-Proto: http\\n\\tConnection: close\\n\\tContent-Length: 0\\n\\tUser-Agent: python-requests/2.22.0\\n\\tAccept: */*\\n\\tAccept-Encoding: gzip, deflate\\n\\tContent-Type: application/json\\n\\tX-Ms-Request-Id: 5b099da9-e00c-4ea0-8d6b-d3de55947981\\nScoring Timer is set to 60.0 seconds\\nEncountered Exception: Traceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 73, in parse_json_input\\n    return pd.read_json(json_input, orient=orient, dtype=False)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 592, in read_json\\n    result = json_reader.read()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 717, in read\\n    obj = self._get_object_parser(self.data)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 739, in _get_object_parser\\n    obj = FrameParser(json, **kwargs).parse()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 849, in parse\\n    self._parse_no_numpy()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 1098, in _parse_no_numpy\\n    for k, v in loads(json, precise_float=self.precise_float).items()\\nValueError: Expected object or value\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/var/azureml-server/app.py\", line 226, in run_scoring\\n    response = invoke_user_with_timer(service_input, request_headers)\\n  File \"/var/azureml-server/app.py\", line 296, in invoke_user_with_timer\\n    result = user_main.run(**params)\\n  File \"/var/azureml-app/main.py\", line 30, in run\\n    return_obj = driver_module.run(**arguments)\\n  File \"/var/azureml-app/execution_script.py\", line 16, in run\\n    input_df = parse_json_input(json_input=json_input, orient=\"split\")\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 81, in parse_json_input\\n    error_code=MALFORMED_REQUEST)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\", line 144, in _handle_serving_error\\n    stack_trace=traceback_buf.getvalue()))\\n  File \"/opt/miniconda/lib/python3.6/site-packages/six.py\", line 696, in reraise\\n    raise value\\nmlflow.exceptions.MlflowException: Failed to parse input as a Pandas DataFrame. Ensure that the input is a valid JSON-formatted Pandas DataFrame with the `split` orient produced using the `pandas.DataFrame.to_json(..., orient=\\'split\\')` method.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1612, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/flask/app.py\", line 1598, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File \"/var/azureml-server/app.py\", line 143, in score_realtime\\n    return run_scoring(service_input, request.headers, request.environ.get(\\'REQUEST_ID\\', \\'00000000-0000-0000-0000-000000000000\\'))\\n  File \"/var/azureml-server/app.py\", line 239, in run_scoring\\n    raise RunFunctionException(str(exc))\\nrun_function_exception.RunFunctionException\\n\\n500\\n127.0.0.1 - - [09/Dec/2019:14:58:19 +0000] \"POST /score HTTP/1.0\" 500 208 \"-\" \"python-requests/2.22.0\"\\nException in worker process\\nTraceback (most recent call last):\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 557, in spawn_worker\\n    worker.init_process()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 132, in init_process\\n    self.run()\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 124, in run\\n    self.run_for_one(timeout)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 83, in run_for_one\\n    self.wait(timeout)\\n  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 35, in wait\\n    ret = select.select(self.wait_fds, [], [], timeout)\\n  File \"/var/azureml-server/app.py\", line 266, in alarm_handler\\n    raise TimeoutException(error_message)\\ntimeout_exception.TimeoutException\\nWorker exiting (pid: 55)\\nworker timeout is set to 300\\nBooting worker with pid: 60\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2019-12-09 14:59:21,921 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2019-12-09 14:59:21,921 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2019-12-09 14:59:21,921 | azureml.core.model | DEBUG | Using passed in version 5\\n2019-12-09 14:59:21,921 | azureml.core.model | DEBUG | Found model path at azureml-models/diabetes-sklearn-model/5/model\\nUsers\\'s init has completed successfully\\n/var/azureml-app/execution_script.py:12: DeprecationWarning: .. Warning:: ``mlflow.pyfunc.load_pyfunc`` is deprecated since 1.0. This method will be removed in a near future release. Use ``mlflow.pyfunc.load_model`` instead.\\n  model = load_pyfunc(model_path)\\nScoring timeout is found from os.environ: 60000 ms\\nValidation Request Content-Type\\nReceived input: {\"columns\":[0,1,2,3,4,5,6,7,8,9],\"index\":[0,1,2],\"data\":[[0.01991321,0.05068012,0.10480869,0.07007254,-0.03596778,-0.0266789,-0.02499266,-0.00259226,0.00371174,0.04034337],[-0.01277963,-0.04464164,0.06061839,0.05285819,0.04796534,0.02937467,-0.01762938,0.03430886,0.0702113,0.00720652],[0.03807591,0.05068012,0.00888341,0.04252958,-0.04284755,-0.02104223,-0.03971921,-0.00259226,-0.01811827,0.00720652]]}\\nHeaders passed in (total 11):\\n\\tHost: localhost:5001\\n\\tX-Real-Ip: 127.0.0.1\\n\\tX-Forwarded-For: 127.0.0.1\\n\\tX-Forwarded-Proto: http\\n\\tConnection: close\\n\\tContent-Length: 404\\n\\tUser-Agent: python-requests/2.22.0\\n\\tAccept: */*\\n\\tAccept-Encoding: gzip, deflate\\n\\tContent-Type: application/json\\n\\tX-Ms-Request-Id: 558f928c-ef4b-4876-8b5c-eac0f467c773\\nScoring Timer is set to 60.0 seconds\\n200\\n127.0.0.1 - - [09/Dec/2019:15:00:03 +0000] \"POST /score HTTP/1.0\" 200 58 \"-\" \"python-requests/2.22.0\"\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webservice.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "shipatel"
   }
  ],
  "category": "deployment",
  "compute": [
   "None"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "Azure Container Instance"
  ],
  "exclude_from_index": false,
  "framework": [
   "Scikit-learn"
  ],
  "friendly_name": "Deploy a model as a web service using MLflow",
  "index_order": 4,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Use MLflow with AML"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
